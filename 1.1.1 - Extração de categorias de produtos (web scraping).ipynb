{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640a6f02",
   "metadata": {},
   "source": [
    "A última execução deste notebook foi em  18 de fevereiro de 2022, às 15∶02∶19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "051979d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from string import digits\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f924d298",
   "metadata": {},
   "source": [
    "Aqui é realizado web scraping no site de quatro super mercados de Fortaleza para montagem de uma lista de nomes de produtos e suas categorias. O resultado final é armazenado em um arquivo csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590581e0",
   "metadata": {},
   "source": [
    "# Função para tratamento dos nomes dos produtos\n",
    "Primeiramente vamos criar uma função que transforma uma string deixando-a toda com caracteres minúsculos e\n",
    "removendo dígitos, acentos e caracteres de pontuação. Também removeremos expressões que referem-se em unidades e\n",
    "medidas, e não à natureza do produto em si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "200db156",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_unidades = ['unidade','kg','caixa','litro','pacote','embalagem','frasco','cx','garrafa','preco','desconto',\n",
    "                'vidro','bandeja','higienizado','higienizada','higienziada','higienizados','selecionada',\n",
    "                'selecionado']\n",
    "sg_unidades = ['g','un','l','ml','s']\n",
    "\n",
    "def trata_str(string):\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    nome_prod = regex.sub('',unidecode(string.translate(str.maketrans('', '', digits)).lower()))\n",
    "    \n",
    "    for sg in sg_unidades:\n",
    "        nome_prod = nome_prod.replace(' ' + sg + ' ','')\n",
    "        if nome_prod[(len(sg) +1) * -1:] == ' ' + sg:\n",
    "            nome_prod = nome_prod[0:len(sg) * -1:]\n",
    "    \n",
    "    for palavra in pal_unidades:\n",
    "        nome_prod = nome_prod.replace(palavra,'')\n",
    "    \n",
    "    nome_prod = re.sub(' +',' ',nome_prod) # Retirando espaços múltiplos.\n",
    "    return nome_prod.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf07d3ba",
   "metadata": {},
   "source": [
    "# Dados de quatro supermercados situados em Fortaleza\n",
    "Vamos ler os produtos disponívels em quatro supermercados para capturar categorias de produtos. Foram escolhidos mercados de Fortaleza pois a massa que estamos tratando trata-se de pedidos de feiras feitos nesta cidade, e podemos ter produtos ou termos específicos da região na nossa massa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "82926c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Tratando https://amercado.americanas.com.br/produtos/centerbox-conceito\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "ERRO 503 em https://amercado.americanas.com.br/produtos/centerbox-conceito/setores\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'links_categorias' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25775/1411454681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m dic_prods1 = busca_produtos1(['https://amercado.americanas.com.br/produtos/centerbox-conceito',\n\u001b[0m\u001b[1;32m     88\u001b[0m                            \u001b[0;34m'https://amercado.americanas.com.br/produtos/hipermercado-big-bompreco-bezerra-de-menezes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                            \u001b[0;34m'https://amercado.americanas.com.br/produtos/pao-de-acucar-nautico'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25775/1411454681.py\u001b[0m in \u001b[0;36mbusca_produtos1\u001b[0;34m(lista_urls)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlink_cat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlinks_categorias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink_cat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'links_categorias' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Recebe uma lista de URLs e faz varredura de todos produtos nelas, retornando um dicionário com os produtos e suas\n",
    "# categorias.\n",
    "def busca_produtos1(lista_urls):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\"}\n",
    "    prods = dict()\n",
    "    qt_erros = int()\n",
    "\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "    s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    # Buscando categorias na páginas principal.\n",
    "    for url_ent in lista_urls:\n",
    "        url = url_ent + '/setores'\n",
    "        print('-'*115)\n",
    "        print(f\"Tratando {url_ent}\")\n",
    "        print('-'*115)\n",
    "        response = s.get(url,headers=headers)\n",
    "\n",
    "        if response.ok:\n",
    "            html = response.content.decode()\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "            links = soup.find_all('li')\n",
    "    \n",
    "            nomes_categorias = list()\n",
    "            links_categorias = list()\n",
    "\n",
    "            for link in links:\n",
    "                nomes_categorias.append(link.get('id'))\n",
    "                link_parcial = link.find_all('a')[0].get('href')\n",
    "                links_categorias.append(url_ent + link_parcial[1:])\n",
    "            print(f\"Categorias lidas: {len(nomes_categorias)}.\")\n",
    "        else:\n",
    "            print(f\"ERRO {response.status_code} em {url}\")\n",
    "            qt_erros += 1\n",
    "            \n",
    "        # Buscando subcategorias nas páginas de categorias\n",
    "        nomes_sub_cats = list()\n",
    "        links_sub_cats = list()\n",
    "        i = int()\n",
    "\n",
    "        for link_cat in links_categorias:\n",
    "            url = link_cat\n",
    "\n",
    "            response = s.get(url,headers=headers)\n",
    "\n",
    "            if response.ok:\n",
    "                html = response.content.decode()\n",
    "                soup = BeautifulSoup(html,'html.parser')\n",
    "                links = soup.find_all('li')\n",
    "    \n",
    "                for link in links:\n",
    "                    nomes_sub_cats.append(link.get('id'))\n",
    "                    link_parcial = link.find_all('a')[0].get('href')\n",
    "                    links_sub_cats.append(url_ent + link_parcial[1:])\n",
    "                print(f\"Tratou {nomes_categorias[i]}. Subcategorias lidas: {len(links)}.\")\n",
    "                i += 1\n",
    "            else:\n",
    "                print(f\"ERRO {response.status_code} em {link_cat}\")\n",
    "                qt_erros += 1\n",
    "\n",
    "        # Buscando produtos nas páginas de subcategorias\n",
    "        sub_cats = list(zip(nomes_sub_cats,links_sub_cats)) # pos[0]: nome; pos[1]: link\n",
    "        \n",
    "        for sub_cat in sub_cats:\n",
    "            url = sub_cat[1]\n",
    "            response = s.get(url,headers=headers)\n",
    "\n",
    "            if response.ok:\n",
    "                html = response.content.decode()\n",
    "                soup = BeautifulSoup(html,'html.parser')\n",
    "                produtos = soup.find_all('div', class_='sc-eCssSg dCfzHX')\n",
    "                for produto in produtos:\n",
    "                    prods[trata_str(produto.text)] = sub_cat[0].split('/')[-1].replace('-',' ')\n",
    "                print(f\"Tratou {sub_cat[0]}. Produtos lidos: {len(produtos)}.\")\n",
    "            else:\n",
    "                print(f\"ERRO {response.status_code} em {sub_cat[1]}\")\n",
    "                qt_erros += 1\n",
    "                \n",
    "    print('-'*115)\n",
    "    print('Final de processamento')\n",
    "    print(f\"Erros ao acessar urls: {qt_erros}\")\n",
    "    print(f\"Total de produtos lidos: {len(prods)}\")\n",
    "    print('-'*115)\n",
    "    return prods\n",
    "\n",
    "dic_prods1 = busca_produtos1(['https://amercado.americanas.com.br/produtos/centerbox-conceito',\n",
    "                           'https://amercado.americanas.com.br/produtos/hipermercado-big-bompreco-bezerra-de-menezes',\n",
    "                           'https://amercado.americanas.com.br/produtos/pao-de-acucar-nautico',\n",
    "                           'https://amercado.americanas.com.br/produtos/mercado-extra-rodoviaria'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef14dc0",
   "metadata": {},
   "source": [
    "# Captura de dados em sites específicos de feiras\n",
    "Como os produtos ofertados em supermercados não são exatamente iguais aos ofertados em feiras, vamos acrescentar informação coletadas em sites específicos de feiras à nossa massa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d2454",
   "metadata": {},
   "source": [
    "## Sos Feira\n",
    "Fonte: https://www.sosfeira.com.br/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96df29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tratando https://www.sosfeira.com.br/frutas\n",
      "Tratando https://www.sosfeira.com.br/verduras\n",
      "Tratando https://www.sosfeira.com.br/legumes\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Final de processamento\n",
      "Erros ao acessar urls: 0\n",
      "Total de produtos lidos: 45\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def busca_produtos2(lista_urls):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\"}\n",
    "    prods = dict()\n",
    "    qt_erros = int()\n",
    "\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "    s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    for url_ent in lista_urls:\n",
    "        print(f\"Tratando {url_ent}\")\n",
    "        response = s.get(url_ent,headers=headers)\n",
    "\n",
    "        if response.ok:\n",
    "            html = response.content.decode()\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "            \n",
    "            categ = soup.find_all('h1', class_='titulo cor-secundaria')\n",
    "            categoria = categ[0].text\n",
    "            \n",
    "            produtos = soup.find_all('div', class_='imagem-produto has-zoom')\n",
    "            for produto in produtos:\n",
    "                produto = produto.find_all('img')[0].get('alt')\n",
    "                \n",
    "                produto = trata_str(produto)\n",
    "                categoria = trata_str(categoria)\n",
    "                prods[produto] = categoria\n",
    "        else:\n",
    "            print(f\"ERRO {response.status_code} em {url_ent}\")\n",
    "            qt_erros += 1\n",
    "\n",
    "    print('-'*115)\n",
    "    print('Final de processamento')\n",
    "    print(f\"Erros ao acessar urls: {qt_erros}\")\n",
    "    print(f\"Total de produtos lidos: {len(prods)}\")\n",
    "    print('-'*115)\n",
    "    return prods\n",
    "\n",
    "\n",
    "dic_prods2 = busca_produtos2(['https://www.sosfeira.com.br/frutas',\n",
    "                            'https://www.sosfeira.com.br/verduras',\n",
    "                            'https://www.sosfeira.com.br/legumes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b17cb6",
   "metadata": {},
   "source": [
    "## Verduranet\n",
    "Fonte: https://www.verduranet.com/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9a613d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tratando https://www.verduranet.com/product-category/vegetais/\n",
      "Tratando https://www.verduranet.com/product-category/vegetais/page/2\n",
      "Tratando https://www.verduranet.com/product-category/vegetais/page/3\n",
      "Tratando https://www.verduranet.com/product-category/vegetais/page/4\n",
      "Final de categoria com https://www.verduranet.com/product-category/vegetais/page/5\n",
      "Tratando https://www.verduranet.com/product-category/frutas/\n",
      "Tratando https://www.verduranet.com/product-category/frutas/page/2\n",
      "Final de categoria com https://www.verduranet.com/product-category/frutas/page/3\n",
      "Tratando https://www.verduranet.com/product-category/saladas/\n",
      "Final de categoria com https://www.verduranet.com/product-category/saladas/page/2\n",
      "Tratando https://www.verduranet.com/product-category/temperos/\n",
      "Final de categoria com https://www.verduranet.com/product-category/temperos/page/2\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "Final de processamento\n",
      "Total de produtos lidos: 71\n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def busca_produtos3(lista_urls):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\"}\n",
    "    prods = dict()\n",
    "    qt_erros = int()\n",
    "\n",
    "    s = requests.Session()\n",
    "    retries = Retry(total=5, backoff_factor=1, status_forcelist=[ 502, 503, 504 ])\n",
    "    s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    for url_ent in lista_urls:\n",
    "        url = url_ent\n",
    "        pag = 1\n",
    "        response = s.get(url,headers=headers)\n",
    "\n",
    "        while response.ok:\n",
    "            print(f\"Tratando {url}\")\n",
    "            html = response.content.decode()\n",
    "            soup = BeautifulSoup(html,'html.parser')\n",
    "            \n",
    "            categ = soup.find_all('nav', class_='woocommerce-breadcrumb')[0]\n",
    "            categoria = categ.text.replace('\\t','').replace('\\n','').replace('\\r','').split('/')[1]\n",
    "            \n",
    "            produtos = soup.find_all('div', class_='product-name')\n",
    "            for produto in produtos:\n",
    "                produto = produto.find_all('h2')[0].text\n",
    "                \n",
    "                produto = trata_str(produto)\n",
    "                categoria = trata_str(categoria)\n",
    "                prods[produto] = categoria\n",
    "                \n",
    "            pag += 1\n",
    "            url = url_ent + 'page/' + str(pag)\n",
    "            response = s.get(url,headers=headers)\n",
    "        else:\n",
    "            print(f\"Final de categoria com {url}\")\n",
    "\n",
    "    print('-'*115)\n",
    "    print('Final de processamento')\n",
    "    print(f\"Total de produtos lidos: {len(prods)}\")\n",
    "    print('-'*115)\n",
    "    return prods\n",
    "\n",
    "\n",
    "dic_prods3 = busca_produtos3(['https://www.verduranet.com/product-category/vegetais/',\n",
    "                              'https://www.verduranet.com/product-category/frutas/',\n",
    "                              'https://www.verduranet.com/product-category/saladas/',\n",
    "                              'https://www.verduranet.com/product-category/temperos/'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2680b5ca",
   "metadata": {},
   "source": [
    "# Unificação dos produtos lidos.\n",
    "Além de unificar todos os produtos em um único dicionário, vamos criar um dicionário com alguns livros. Livros estão presentes nos dados que iremos tratar, entretanto não são vendidos nas fontes que consultamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e58d5cad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dic_prods1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25775/2008394642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m              'livro as fronteiras que unem':'livros',}\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdic_prods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic_prods1\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdic_prods2\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdic_prods3\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdic_prods9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dic_prods1' is not defined"
     ]
    }
   ],
   "source": [
    "dic_prods9 = {'livro gato de botas':'livros',\n",
    "             'livro moby dick': 'livros',\n",
    "             'livro as longas trancas de um careca':'livros',\n",
    "             'livro a volta dos que nao foram':'livros',\n",
    "             'livro mamae nao quer que eu case':'livros',\n",
    "             'livro as aventuras de um aventureiro':'livros',\n",
    "             'livro as desventuras de um azarado':'livros',\n",
    "             'livro o cachorro sapeca':'livros',\n",
    "             'livro o gato que miava au au':'livros',\n",
    "             'livro o suspiro do doceiro':'livros',\n",
    "             'livro as desventuras de um azarado':'livros',\n",
    "             'livro as fronteiras que unem':'livros',}\n",
    "\n",
    "dic_prods = dic_prods1 | dic_prods2 | dic_prods3 | dic_prods9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9347183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3a51ec5",
   "metadata": {},
   "source": [
    "# Análise das categorias levantadas\n",
    "Vamos ver se existem categorias muito parecidas ou inócuas. Caso positivo, trataremos para termos dados com a melhor qualidade possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc95d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame.from_dict(dic_prods,orient='index')\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['produto','categoria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe4f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(df['categoria'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ec2660",
   "metadata": {},
   "source": [
    "Faremos as seguintes intervenções:\n",
    "- remover \"espaco mondelez\";\n",
    "- mudar \"ajinomoto\" para \"temperos e condimentos\";\n",
    "- mudar \"categoria maquiagem\" para \"maquiagem\";\n",
    "- mudar \"cervejas ambev\" para \"cervejas\";\n",
    "- mudar \"danone\" para \"iogurtes e coalhadas\";\n",
    "- mudar \"festival do bebe carrefour\" para \"higiene\";\n",
    "- mudar \"higiene bebe\" para \"higiene\";\n",
    "- mudar \"johnson and johnson\" para \"higiene\";\n",
    "- mudar \"hortifruti manipulados\" para \"hortifruti\";\n",
    "- mudar \"mais hortifruti\" para \"hortifruti\";\n",
    "- mudar \"mars\" para \"petshop\";\n",
    "- mudar \"petshop aves\" para \"petshop\";\n",
    "- mudar \"petshop caes\" para \"petshop\";\n",
    "- mudar \"petshop gatos\" para \"petshop\";\n",
    "- mudar \"papel aluminio papel manteiga\" para \"embalagens\";\n",
    "- mudar \"filme pvc sacos plasticos\" para \"embalagens\";\n",
    "- mudar \"padaria fabricacao propria\" para \"paes\";\n",
    "- mudar \"prudence\" para \"preservativos correlatos\";\n",
    "- mudar \"pratos prontos\" para \"pronto para consumo\";\n",
    "- mudar \"sobremesas lacteas\" para \"sorvetes sucos e sobremesas\";\n",
    "- mudar \"whisky\" para \"destilados\";\n",
    "- mudar \"drinks\" para \"destilados\";\n",
    "- mudar \"doces padaria\" para \"doces e sobremesas\";\n",
    "- mudar \"embutidos finos\" para \"frios e embutidos\";\n",
    "- mudar \"outros utilidades domesticas\" para \"uso geral\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01843731",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a1b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['categoria'] == 'espaco mondelez'].index,inplace=True)\n",
    "\n",
    "trocas = {\"ajinomoto\":\"temperos e condimentos\",\n",
    "\"categoria maquiagem\":\"maquiagem\",\n",
    "\"cervejas ambev\":\"cervejas\",\n",
    "\"danone\":\"iogurtes e coalhadas\",\n",
    "\"festival do bebe carrefour\":\"higiene\",\n",
    "\"higiene bebe\":\"higiene\",\n",
    "\"johnson and johnson\":\"higiene\",\n",
    "\"hortifruti manipulados\":\"hortifruti\",\n",
    "\"mais hortifruti\":\"hortifruti\",\n",
    "\"mars\":\"petshop\",\n",
    "\"petshop aves\":\"petshop\",\n",
    "\"petshop caes\":\"petshop\",\n",
    "\"petshop gatos\":\"petshop\",\n",
    "\"papel aluminio papel manteiga\":\"embalagens\",\n",
    "\"filme pvc sacos plasticos\":\"embalagens\",\n",
    "\"padaria fabricacao propria\":\"paes\",\n",
    "\"prudence\":\"preservativos correlatos\",\n",
    "\"pratos prontos\":\"pronto para consumo\",\n",
    "\"sobremesas lacteas\":\"sorvetes sucos e sobremesas\",\n",
    "\"whisky\":\"destilados\",\n",
    "\"drinks\":\"destilados\",\n",
    "\"doces padaria\":\"doces e sobremesas\",\n",
    "\"embutidos finos\":\"frios e embutidos\",\n",
    "\"outros utilidades domesticas\":\"uso geral\"}\n",
    "\n",
    "df['categoria'].replace(trocas,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a05cb",
   "metadata": {},
   "source": [
    "# Salvando os dados em arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3105fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='produto',inplace=True) # Para misturar os produtos dos diferentes mercados entre si.\n",
    "df.to_csv('arquivos/produtos_categorias.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
